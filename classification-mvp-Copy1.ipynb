{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _sklearn fbeta score â€“ f2 or f3 to upweight recall_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 6 | Model Iteration #2: Decision Trees <a id='6'></a>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # fit decision tree on scaled dummy X train/train\n",
    "\n",
    "# tree = DecisionTreeClassifier(criterion = 'gini', random_state = 0)\n",
    "# tree.fit(X_train_scaled_d, X_test_scaled_d)\n",
    "\n",
    "# ValueError: Unknown label type: 'continuous-multioutput'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # classification report dummy \n",
    "# classify_logreg = classification_report(y_pred_logreg_d, y_pred_proba_logreg_d)\n",
    "\n",
    "# print(classify_logreg)\n",
    "# # ValueError: Classification metrics can't handle a mix of binary and continuous-multioutput targets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # predict/proba on dummy X test scaled\n",
    "# y_pred_logreg_d =       logreg_dmy.predict(X_test_scaled_d)\n",
    "# y_pred_proba_logreg_d = logreg_dmy.predict_proba(X_test_scaled_d)\n",
    "\n",
    "# print(f1_score(y_pred_logreg_d, y_pred_proba_logreg_d, average=\"macro\"))\n",
    "\n",
    "# ValueError: Classification metrics can't handle a mix of binary and continuous-multioutput targets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/laramillernm/Metis-Classification-Project/blob/main/TelcoChurnFinal.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model with all features\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "y_pred_lr = logreg.predict(X_test)\n",
    "y_prob_pred_test = logreg.predict_proba(X_test)\n",
    "\n",
    "print(f1_score(y_test, y_pred_lr, average=\"macro\"))\n",
    "\n",
    "\n",
    "# classification report \n",
    "\n",
    "classify_logreg = classification_report(y_test, y_pred_lr)\n",
    "print(classify_logreg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale X_train and X_test\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "# fit decision tree to X_train, y_train\n",
    "\n",
    "classifier = DecisionTreeClassifier(criterion = 'gini', random_state = 0)\n",
    "classifier.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on X_test\n",
    "\n",
    "y_pred_dt = classifier.predict(X_test)\n",
    "print(f1_score(y_test, y_pred_dt, average=\"macro\"))\n",
    "\n",
    "\n",
    "# classification report \n",
    "\n",
    "classify_dt = classification_report(y_test, y_pred_dt)\n",
    "print(classify_dt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/hyewonjng/Metis-Vaccination/blob/main/codes/2_classification_models.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split X and y twice for Xy_train, Xy_test, Xy_validate sets\n",
    "\n",
    "y = df.series\n",
    "X = df.drop(labels = ['column_name', 'column_name'], axis = 1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size = .2, random_state = 42, stratify= y)\n",
    "\n",
    "X_train, X_validate, y_train, y_validate = train_test_split(X_train, y_train, \n",
    "                                                            test_size = .25, random_state = 42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BernoulliNB() \n",
    "\n",
    "# scale X_train \n",
    "std_scale = StandardScaler()\n",
    "X_train_scaled = std_scale.fit_transform(X_train)\n",
    "\n",
    "# fit and score naive bayes Bernoulli model on X_train_scaled, y_train\n",
    "nb = BernoulliNB()\n",
    "nb.fit(X_train_scaled, y_train)\n",
    "nb.score(X_train_scaled, y_train)\n",
    "\n",
    "# validate naive bayes Bernoulli model\n",
    "std_scale = StandardScaler()\n",
    "X_validate_scaled = std_scale.fit_transform(X_validate)\n",
    "\n",
    "# fit and score naive bayes Bernoulli model on X_validate_scaled, y_validate\n",
    "nb = BernoulliNB()\n",
    "nb.fit(X_validate_scaled, y_validate)\n",
    "nb.score(X_validate_scaled, y_validate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BernoulliNB() \n",
    "# predict on X_validate_scaled and score y_validate, y_predict with all metrics\n",
    "\n",
    "y_predict = nb.predict(X_validate_scaled) \n",
    "\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_validate, y_predict))\n",
    "print(\"Precision:\",metrics.precision_score(y_validate, y_predict))\n",
    "print(\"Recall:\",metrics.recall_score(y_validate, y_predict))\n",
    "print(\"F1:\",metrics.f1_score(y_validate, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LogisticRegression()\n",
    "# scale X_train\n",
    "\n",
    "std_scale = StandardScaler()\n",
    "X_train_scaled = std_scale.fit_transform(X_train)\n",
    "\n",
    "logit = LogisticRegression(C=1000) # high C removes regularization\n",
    "logit.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_predict = logit.predict(X_train_scaled) \n",
    "logit.score(X_train_scaled, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LogisticRegression()\n",
    "# scale X_val \n",
    "\n",
    "std_scale = StandardScaler()\n",
    "X_val_scaled = std_scale.fit_transform(X_val)\n",
    "\n",
    "logit = LogisticRegression(C=1000) # high C removes regularization\n",
    "logit.fit(X_val_scaled, y_val)\n",
    "logit.score(X_val_scaled, y_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_val, logit.predict_proba(X_val_scaled)[:,1])\n",
    "\n",
    "plt.plot(fpr, tpr,lw=2)\n",
    "plt.plot([0,1],[0,1],c='violet',ls='--')\n",
    "plt.xlim([-0.05,1.05])\n",
    "plt.ylim([-0.05,1.05])\n",
    "\n",
    "\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve');\n",
    "print(\"ROC AUC score = \", roc_auc_score(y_val, logit.predict_proba(X_val_scaled)[:,1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class imbalance\n",
    "\n",
    "# setup for the ratio argument of RandomOverSampler initialization SMOTE\n",
    "n_pos = np.sum(y_train == 1)\n",
    "n_neg = np.sum(y_train == 0)\n",
    "ratio = {1 : n_pos * 3, 0 : n_neg} \n",
    "\n",
    "smote = imblearn.over_sampling.SMOTE(sampling_strategy = ratio, random_state = 42)\n",
    "\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "nb_smote = BernoulliNB() \n",
    "nb_smote.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "print('Logistic Regression on SMOTE Train Data; Test Recall: %.3f, Test AUC: %.3f' % \\\n",
    "      (recall_score(y_validate, nb_smote.predict(X_validate_scaled)), \n",
    "       roc_auc_score(y_validate, nb_smote.predict_proba(X_validate_scaled)[:,1])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance\n",
    "\n",
    "importance = logit.coef_[0]\n",
    "\n",
    "# summarize feature importance\n",
    "for i,v in enumerate(importance):\n",
    "    print('Feature: %0d, Score: %.5f' % (i,v))\n",
    "    \n",
    "# plot feature importance\n",
    "plt.bar([x for x in range(len(importance))], importance)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_confusion_matrix(model, threshold=0.5):\n",
    "    \n",
    "    # Predict class 1 if probability of being in class 1 is greater than threshold\n",
    "    # (model.predict(X_test) does this automatically with a threshold of 0.5)\n",
    "    \n",
    "    y_predict = (model.predict_proba(X_test_scaled)[:, 1] >= threshold)\n",
    "    fraud_confusion = confusion_matrix(y_test, y_predict)\n",
    "    plt.figure(dpi=80)\n",
    "    sns.heatmap(fraud_confusion, cmap=plt.cm.BuGn, annot=True, square=True, fmt='d',\n",
    "           xticklabels=['non-vaccinated', 'vaccinated'],\n",
    "           yticklabels=['non-vaccinated', 'vaccinated']);\n",
    "    plt.xlabel('prediction')\n",
    "    plt.ylabel('actual')\n",
    "\n",
    "make_confusion_matrix(rf) #rf = random forest model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\",metrics.precision_score(y_test, y_pred))\n",
    "print(\"Recall:\",metrics.recall_score(y_test, y_pred))\n",
    "print(\"f1:\",metrics.f1_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/emichaelbernardo/titanic/blob/main/Classification.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize data\n",
    "\n",
    "cols = ['AgeGroup', 'Sex', 'Pclass', 'SibSp', 'Parch', 'Embarked']\n",
    "\n",
    "n_rows = 2\n",
    "n_cols = 3\n",
    "\n",
    "# The subplot grid and the figure size of each graph\n",
    "# This returns a Figure (fig) and an Axes Object (axs)\n",
    "fig, axs = plt.subplots(n_rows, n_cols, figsize=(n_cols*3.2,n_rows*3.2))\n",
    "\n",
    "for r in range(0,n_rows):\n",
    "    for c in range(0,n_cols):  \n",
    "        \n",
    "        i = r*n_cols+ c # index to go through the number of columns       \n",
    "        ax = axs[r][c]  # Show where to position each subplot\n",
    "        sns.countplot(df_passengers[cols[i]], hue=df_passengers[\"Survived\"], ax=ax)\n",
    "        ax.set_title(f'Survival by {cols[i]}' )\n",
    "        ax.legend(title=\"Survived\", loc='upper right') \n",
    "        \n",
    "plt.tight_layout()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View distribution of passengers\n",
    "sns.factorplot(y = 'Age', x = 'Sex', hue = 'Pclass', kind = 'box', data = df_passengers).set(title='Distribution by Age, Sex and Pclass')\n",
    "sns.factorplot(y = 'Age', x = 'Parch', hue='Sex', kind = 'box', data = df_passengers).set(title='Distribution by Age and Parch')\n",
    "sns.factorplot(y = 'Age', x = 'SibSp', kind = 'box', data = df_passengers).set(title='Distribution by Age and SibSp')\n",
    "sns.factorplot(y = 'Age', x = 'Embarked', kind = 'box', data = df_passengers).set(title='Distribution by Age and Embarked')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions to score models\n",
    "\n",
    "def accuracy(actuals, preds):\n",
    "    return np.mean(actuals == preds)\n",
    "\n",
    "def precision(actuals, preds):\n",
    "    tp = np.sum((actuals == 1) & (preds == 1))\n",
    "    fp = np.sum((actuals == 0) & (preds == 1))\n",
    "    return tp / (tp + fp)\n",
    "\n",
    "def recall(actuals, preds):\n",
    "    tp = np.sum((actuals == 1) & (preds == 1))\n",
    "    fn = np.sum((actuals == 1) & (preds == 0))\n",
    "    return tp / (tp + fn)\n",
    "\n",
    "def F1(actuals, preds):\n",
    "    p, r = precision(actuals, preds), recall(actuals, preds)\n",
    "    return 2*p*r / (p + r)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[back to top](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Preliminary Visualization<a id='3'></a> \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[back to top](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Preliminary Conclusions<a id='4'></a> \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[back to top](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "288px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
