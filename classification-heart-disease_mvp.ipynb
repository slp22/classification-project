{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification | MVP\n",
    "\n",
    "# Predicting Heart Disease<a id='top'></a> \n",
    "\n",
    "\n",
    "## **Analysis Goal**  \n",
    "[Research question](#1)\n",
    "\n",
    "## **Process**\n",
    "\n",
    "Classification metric â€“ \n",
    "AUC = determining the 'most at risk' (say top 100) by ordering by liklihood \n",
    "F1/recall = providing a concrete label (either at risk or not at risk) \n",
    "\n",
    "\n",
    "[Dataset](#2)\n",
    "\n",
    "## **Preliminary Visualization**\n",
    "[Visualization](#3)\n",
    "\n",
    "## **Preliminary Conclusions**\n",
    "[Conclusion](#4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import imblearn.over_sampling\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.ensemble import AdaBoostRegressor, RandomForestClassifier\n",
    "from sklearn.linear_model import LinearRegression ,LogisticRegression\n",
    "from sklearn.metrics import *\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB, GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, OrdinalEncoder\n",
    "from sklearn.svm import SVC ,SVR\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.utils import shuffle\n",
    "# from xgboost import XGBClassifier\n",
    "\n",
    "# import plotly.express as px\n",
    "# import plotly.graph_objects as go\n",
    "# from plotly.subplots import make_subplots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Research Question<a id='1'></a> \n",
    "\n",
    "* **RQ:** Could a model predict the probability of a patient having heart disease based on the risk factors in electronic health records?\n",
    "* **Data source:** [Personal Key Indicators of Heart Disease](https://www.kaggle.com/datasets/kamilpytlak/personal-key-indicators-of-heart-disease)\n",
    "* **Error metric:** Recall\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[back to top](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Dataset: [Personal Key Indicators of Heart Disease](https://www.kaggle.com/datasets/kamilpytlak/personal-key-indicators-of-heart-disease)<a id='2'></a>  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('heart_2020_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeartDisease        0\n",
       "BMI                 0\n",
       "Smoking             0\n",
       "AlcoholDrinking     0\n",
       "Stroke              0\n",
       "PhysicalHealth      0\n",
       "MentalHealth        0\n",
       "DiffWalking         0\n",
       "Sex                 0\n",
       "AgeCategory         0\n",
       "Race                0\n",
       "Diabetes            0\n",
       "PhysicalActivity    0\n",
       "GenHealth           0\n",
       "SleepTime           0\n",
       "Asthma              0\n",
       "KidneyDisease       0\n",
       "SkinCancer          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find nulls\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HeartDisease</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Smoking</th>\n",
       "      <th>AlcoholDrinking</th>\n",
       "      <th>Stroke</th>\n",
       "      <th>PhysicalHealth</th>\n",
       "      <th>MentalHealth</th>\n",
       "      <th>DiffWalking</th>\n",
       "      <th>Sex</th>\n",
       "      <th>AgeCategory</th>\n",
       "      <th>Race</th>\n",
       "      <th>Diabetes</th>\n",
       "      <th>PhysicalActivity</th>\n",
       "      <th>GenHealth</th>\n",
       "      <th>SleepTime</th>\n",
       "      <th>Asthma</th>\n",
       "      <th>KidneyDisease</th>\n",
       "      <th>SkinCancer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>319795.000000</td>\n",
       "      <td>319795.000000</td>\n",
       "      <td>319795.000000</td>\n",
       "      <td>319795.000000</td>\n",
       "      <td>319795.000000</td>\n",
       "      <td>319795.00000</td>\n",
       "      <td>319795.000000</td>\n",
       "      <td>319795.000000</td>\n",
       "      <td>319795.000000</td>\n",
       "      <td>319795.000000</td>\n",
       "      <td>319795.000000</td>\n",
       "      <td>319795.000000</td>\n",
       "      <td>319795.000000</td>\n",
       "      <td>319795.000000</td>\n",
       "      <td>319795.000000</td>\n",
       "      <td>319795.000000</td>\n",
       "      <td>319795.000000</td>\n",
       "      <td>319795.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.085595</td>\n",
       "      <td>28.325399</td>\n",
       "      <td>0.412477</td>\n",
       "      <td>0.068097</td>\n",
       "      <td>0.037740</td>\n",
       "      <td>3.37171</td>\n",
       "      <td>3.898366</td>\n",
       "      <td>0.138870</td>\n",
       "      <td>1.475273</td>\n",
       "      <td>52.440945</td>\n",
       "      <td>5.396742</td>\n",
       "      <td>0.207205</td>\n",
       "      <td>0.775362</td>\n",
       "      <td>3.595028</td>\n",
       "      <td>7.097075</td>\n",
       "      <td>0.134061</td>\n",
       "      <td>0.036833</td>\n",
       "      <td>0.093244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.279766</td>\n",
       "      <td>6.356100</td>\n",
       "      <td>0.492281</td>\n",
       "      <td>0.251912</td>\n",
       "      <td>0.190567</td>\n",
       "      <td>7.95085</td>\n",
       "      <td>7.955235</td>\n",
       "      <td>0.345812</td>\n",
       "      <td>0.499389</td>\n",
       "      <td>18.069747</td>\n",
       "      <td>1.212208</td>\n",
       "      <td>0.554528</td>\n",
       "      <td>0.417344</td>\n",
       "      <td>1.042918</td>\n",
       "      <td>1.436007</td>\n",
       "      <td>0.340718</td>\n",
       "      <td>0.188352</td>\n",
       "      <td>0.290775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.020000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>24.030000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.340000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.420000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>94.850000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>30.00000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        HeartDisease            BMI        Smoking  AlcoholDrinking  \\\n",
       "count  319795.000000  319795.000000  319795.000000    319795.000000   \n",
       "mean        0.085595      28.325399       0.412477         0.068097   \n",
       "std         0.279766       6.356100       0.492281         0.251912   \n",
       "min         0.000000      12.020000       0.000000         0.000000   \n",
       "25%         0.000000      24.030000       0.000000         0.000000   \n",
       "50%         0.000000      27.340000       0.000000         0.000000   \n",
       "75%         0.000000      31.420000       1.000000         0.000000   \n",
       "max         1.000000      94.850000       1.000000         1.000000   \n",
       "\n",
       "              Stroke  PhysicalHealth   MentalHealth    DiffWalking  \\\n",
       "count  319795.000000    319795.00000  319795.000000  319795.000000   \n",
       "mean        0.037740         3.37171       3.898366       0.138870   \n",
       "std         0.190567         7.95085       7.955235       0.345812   \n",
       "min         0.000000         0.00000       0.000000       0.000000   \n",
       "25%         0.000000         0.00000       0.000000       0.000000   \n",
       "50%         0.000000         0.00000       0.000000       0.000000   \n",
       "75%         0.000000         2.00000       3.000000       0.000000   \n",
       "max         1.000000        30.00000      30.000000       1.000000   \n",
       "\n",
       "                 Sex    AgeCategory           Race       Diabetes  \\\n",
       "count  319795.000000  319795.000000  319795.000000  319795.000000   \n",
       "mean        1.475273      52.440945       5.396742       0.207205   \n",
       "std         0.499389      18.069747       1.212208       0.554528   \n",
       "min         1.000000      18.000000       1.000000       0.000000   \n",
       "25%         1.000000      40.000000       6.000000       0.000000   \n",
       "50%         1.000000      55.000000       6.000000       0.000000   \n",
       "75%         2.000000      65.000000       6.000000       0.000000   \n",
       "max         2.000000      80.000000       6.000000       3.000000   \n",
       "\n",
       "       PhysicalActivity      GenHealth      SleepTime         Asthma  \\\n",
       "count     319795.000000  319795.000000  319795.000000  319795.000000   \n",
       "mean           0.775362       3.595028       7.097075       0.134061   \n",
       "std            0.417344       1.042918       1.436007       0.340718   \n",
       "min            0.000000       1.000000       1.000000       0.000000   \n",
       "25%            1.000000       3.000000       6.000000       0.000000   \n",
       "50%            1.000000       4.000000       7.000000       0.000000   \n",
       "75%            1.000000       4.000000       8.000000       0.000000   \n",
       "max            1.000000       5.000000      24.000000       1.000000   \n",
       "\n",
       "       KidneyDisease     SkinCancer  \n",
       "count  319795.000000  319795.000000  \n",
       "mean        0.036833       0.093244  \n",
       "std         0.188352       0.290775  \n",
       "min         0.000000       0.000000  \n",
       "25%         0.000000       0.000000  \n",
       "50%         0.000000       0.000000  \n",
       "75%         0.000000       0.000000  \n",
       "max         1.000000       1.000000  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# summary statistics on numeric columns\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename column to not refer to people by their disease\n",
    "df.rename(columns = {'Diabetic':'Diabetes'}, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list unique values by column to see what needs to be coded with numbers\n",
    "\n",
    "for col in df:\n",
    "    print(col, df[col].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code Y/N to 1/0\n",
    "#     HeartDisease\n",
    "#     AlcoholDrinking \n",
    "#     PhysicalHealth \n",
    "#     DiffWalking \n",
    "#     Diabetes -> adjust in next cell for 'borderline diabetes' 'Yes (during pregnancy)'\n",
    "#     PhysicalActivity\n",
    "#     Asthma \n",
    "#     KidneyDisease \n",
    "#     SkinCancer\n",
    "\n",
    "df = df.replace({'Yes': 1, 'No': 0}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code categories to nums Diabetes, Sex, Race (alpha), GenHealth (poor 1, excellent 5)\n",
    "\n",
    "df = df.replace({'Yes (during pregnancy)': 2,           #Diabetes\n",
    "                 'No, borderline diabetes': 3,  \n",
    "                 'Female': 1,                           #Sex \n",
    "                 'Male': 2,                             \n",
    "                 'American Indian/Alaskan Native': 1,  #Race  \n",
    "                 'Asian':2,                     \n",
    "                 'Black':3,                      \n",
    "                 'Hispanic':4,                   \n",
    "                 'Other': 5,                     \n",
    "                 'White': 6,                     \n",
    "                 'Poor': 1,                             #GenHealth\n",
    "                 'Fair': 2,                     \n",
    "                 'Good': 3,                     \n",
    "                 'Very good': 4,                \n",
    "                 'Excellent': 5})               \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code AgeCategory to lowest age of category\n",
    "\n",
    "df = df.replace({'18-24':18,\n",
    "             '25-29':25, \n",
    "             '30-34':30, \n",
    "             '35-39':35, \n",
    "             '40-44':40, \n",
    "             '45-49':45, \n",
    "             '50-54':50,\n",
    "             '55-59':55,\n",
    "             '60-64':60,\n",
    "             '65-69':65,\n",
    "             '70-74':70,\n",
    "             '75-79':75,    \n",
    "             '80 or older':80})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HeartDisease [0 1]\n",
      "BMI [16.6  20.34 26.58 ... 62.42 51.46 46.56]\n",
      "Smoking [1 0]\n",
      "AlcoholDrinking [0 1]\n",
      "Stroke [0 1]\n",
      "PhysicalHealth [ 3.  0. 20. 28.  6. 15.  5. 30.  7.  1.  2. 21.  4. 10. 14. 18.  8. 25.\n",
      " 16. 29. 27. 17. 24. 12. 23. 26. 22. 19.  9. 13. 11.]\n",
      "MentalHealth [30.  0.  2.  5. 15.  8.  4.  3. 10. 14. 20.  1.  7. 24.  9. 28. 16. 12.\n",
      "  6. 25. 17. 18. 21. 29. 22. 13. 23. 27. 26. 11. 19.]\n",
      "DiffWalking [0 1]\n",
      "Sex [1 2]\n",
      "AgeCategory [55 80 65 75 40 70 60 50 45 18 35 30 25]\n",
      "Race [6 3 2 1 5 4]\n",
      "Diabetes [1 0 3 2]\n",
      "PhysicalActivity [1 0]\n",
      "GenHealth [4 2 3 1 5]\n",
      "SleepTime [ 5.  7.  8.  6. 12.  4.  9. 10. 15.  3.  2.  1. 16. 18. 14. 20. 11. 13.\n",
      " 17. 24. 19. 21. 22. 23.]\n",
      "Asthma [1 0]\n",
      "KidneyDisease [0 1]\n",
      "SkinCancer [1 0]\n"
     ]
    }
   ],
   "source": [
    "# list unique values by column to see what needs to be coded with numbers\n",
    "\n",
    "for col in df:\n",
    "    print(col, df[col].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a linear mapping for age, income, etc. \n",
    "\n",
    "Compare performance of the linear mapped approach with dummy variable approach. \n",
    "\n",
    "The logistic_exercise notebook may help with understanding the relationship between the linear nature of features and their predictive power\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate target from select features\n",
    "y = df['HeartDisease']\n",
    "\n",
    "X = df.loc[:, ['BMI', 'Smoking', 'AlcoholDrinking', 'Stroke',\n",
    "       'PhysicalHealth', 'MentalHealth', 'DiffWalking', 'Sex', 'AgeCategory',\n",
    "       'Race', 'Diabetes', 'PhysicalActivity', 'GenHealth', 'SleepTime',\n",
    "       'Asthma', 'KidneyDisease', 'SkinCancer']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 319795 entries, 0 to 319794\n",
      "Series name: HeartDisease\n",
      "Non-Null Count   Dtype\n",
      "--------------   -----\n",
      "319795 non-null  int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 2.4 MB\n"
     ]
    }
   ],
   "source": [
    "y.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 319795 entries, 0 to 319794\n",
      "Data columns (total 17 columns):\n",
      " #   Column            Non-Null Count   Dtype  \n",
      "---  ------            --------------   -----  \n",
      " 0   BMI               319795 non-null  float64\n",
      " 1   Smoking           319795 non-null  int64  \n",
      " 2   AlcoholDrinking   319795 non-null  int64  \n",
      " 3   Stroke            319795 non-null  int64  \n",
      " 4   PhysicalHealth    319795 non-null  float64\n",
      " 5   MentalHealth      319795 non-null  float64\n",
      " 6   DiffWalking       319795 non-null  int64  \n",
      " 7   Sex               319795 non-null  int64  \n",
      " 8   AgeCategory       319795 non-null  int64  \n",
      " 9   Race              319795 non-null  int64  \n",
      " 10  Diabetes          319795 non-null  int64  \n",
      " 11  PhysicalActivity  319795 non-null  int64  \n",
      " 12  GenHealth         319795 non-null  int64  \n",
      " 13  SleepTime         319795 non-null  float64\n",
      " 14  Asthma            319795 non-null  int64  \n",
      " 15  KidneyDisease     319795 non-null  int64  \n",
      " 16  SkinCancer        319795 non-null  int64  \n",
      "dtypes: float64(4), int64(13)\n",
      "memory usage: 41.5 MB\n"
     ]
    }
   ],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split test data set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(pd.concat([X_train, y_train], axis=1), hue='HeartDisease');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# picke df \n",
    "clean_df = df \n",
    "clean_df.to_pickle('clean_df.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv df\n",
    "clean_df.to_csv(r'/Users/sandraparedes/Dropbox/Mac/Downloads/clean_df.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/laramillernm/Metis-Classification-Project/blob/main/TelcoChurnFinal.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change \"total charges to numeric\" \n",
    "df['Total_Charges'] = pd.to_numeric(df['Total_Charges'], errors='coerce')\n",
    "\n",
    "# change zip code to string\n",
    "df['Zip_Code'] = df['Zip_Code'].astype('str')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dummy variables\n",
    "base = pd.get_dummies(data=dftelco_base, columns=['Gender', 'Senior_Citizen', 'Partner', 'Dependents', 'Phone_Service', 'Multiple_Lines', 'Internet_Service',\n",
    "       'Online_Security', 'Online_Backup', 'Device_Protection', 'Tech_Support',\n",
    "       'Streaming_TV', 'Streaming_Movies', 'Contract', 'Paperless_Billing',\n",
    "       'Payment_Method'], drop_first=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base model with all features\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "y_pred_lr = logreg.predict(X_test)\n",
    "y_prob_pred_test = logreg.predict_proba(X_test)\n",
    "\n",
    "print(f1_score(y_test, y_pred_lr, average=\"macro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classify_logreg = classification_report(y_test, y_pred_lr)\n",
    "print(classify_logreg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature scaling\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "# fit decision tree classification to the training set\n",
    "classifier = DecisionTreeClassifier(criterion = 'gini', random_state = 0)\n",
    "classifier.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicting test set\n",
    "y_pred_dt = classifier.predict(X_test)\n",
    "print(f1_score(y_test, y_pred_dt, average=\"macro\"))\n",
    "\n",
    "classify_dt = classification_report(y_test, y_pred_dt)\n",
    "print(classify_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/hyewonjng/Metis-Vaccination/blob/main/codes/2_classification_models.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split X and y twice for train, test, validate sets\n",
    "y = df_2.h1n1_vaccine\n",
    "X = df_2.drop(labels = ['h1n1_vaccine','respondent_id','seasonal_vaccine'], axis = 1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .2, random_state = 42, stratify= y)\n",
    "X_train, X_validate, y_train, y_validate = train_test_split(X_train, y_train, test_size = .25, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale data train data\n",
    "std_scale = StandardScaler()\n",
    "X_train_scaled = std_scale.fit_transform(X_train)\n",
    "\n",
    "# fit and score naive bayes Bernoulli model on train scaled set\n",
    "nb = BernoulliNB()\n",
    "nb.fit(X_train_scaled, y_train)\n",
    "nb.score(X_train_scaled, y_train)\n",
    "\n",
    "# validate naive bayes Bernoulli model\n",
    "std_scale = StandardScaler()\n",
    "X_validate_scaled = std_scale.fit_transform(X_val)\n",
    "\n",
    "# fit and score naive bayes Bernoulli model on validate scaled set\n",
    "nb = BernoulliNB()\n",
    "nb.fit(X_validate_scaled, y_validate)\n",
    "nb.score(X_validate_scaled, y_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on validate scaled set and score with all metrics\n",
    "\n",
    "y_predict = nb.predict(X_validate_scaled) \n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_validate, y_predict))\n",
    "print(\"Precision:\",metrics.precision_score(y_validate, y_predict))\n",
    "print(\"Recall:\",metrics.recall_score(y_validate, y_predict))\n",
    "print(\"F1:\",metrics.f1_score(y_validate, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treating ordinal variables to make sure that they are encoded in the correct orders.\n",
    "\n",
    "education_lvl = [['< 12 Years','12 Years','College Graduate','Some College']]\n",
    "age_lvl = [['18 - 34 Years','35 - 44 Years','45 - 54 Years','55 - 64 Years','65+ Years']]\n",
    "income_lvl = [['Below Poverty','<= $75,000, Above Poverty','> $75,000']]\n",
    "\n",
    "transformer = make_column_transformer(\n",
    "    (OrdinalEncoder(categories=education_lvl), ['education']),\n",
    "    (OrdinalEncoder(categories=age_lvl), ['age_group']),\n",
    "    (OrdinalEncoder(categories=income_lvl), ['income_poverty'])\n",
    ")\n",
    "\n",
    "transformer.fit_transform(df_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating dummy variables for categorical features\n",
    "df_2 = pd.get_dummies(df_2, columns =['race','sex','income_poverty',\n",
    "                                    'marital_status','rent_or_own','employment_status','census_msa','hhs_geo_region',\n",
    "                                     'employment_industry','employment_occupation'], drop_first = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating target and feature variables\n",
    "y = df_2.h1n1_vaccine\n",
    "X = df_2.drop(labels = ['h1n1_vaccine','respondent_id','seasonal_vaccine'], axis = 1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .2, random_state = 42, stratify = y)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = .25, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_scale = StandardScaler()\n",
    "X_train_scaled = std_scale.fit_transform(X_train)\n",
    "\n",
    "logit = LogisticRegression(C=1000) # setting C very high essentially removes regularization\n",
    "logit.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_predict = logit.predict(X_train_scaled) \n",
    "logit.score(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_scale = StandardScaler()\n",
    "X_val_scaled = std_scale.fit_transform(X_val)\n",
    "\n",
    "logit = LogisticRegression(C=1000) # setting C very high essentially removes regularization\n",
    "logit.fit(X_val_scaled, y_val)\n",
    "logit.score(X_val_scaled, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = logit.predict(X_val_scaled) \n",
    "\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_val, y_pred))\n",
    "print(\"Precision:\",metrics.precision_score(y_val, y_pred))\n",
    "print(\"Recall:\",metrics.recall_score(y_val, y_pred))\n",
    "print(\"f1:\",metrics.f1_score(y_val, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_val, logit.predict_proba(X_val_scaled)[:,1])\n",
    "\n",
    "plt.plot(fpr, tpr,lw=2)\n",
    "plt.plot([0,1],[0,1],c='violet',ls='--')\n",
    "plt.xlim([-0.05,1.05])\n",
    "plt.ylim([-0.05,1.05])\n",
    "\n",
    "\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve');\n",
    "print(\"ROC AUC score = \", roc_auc_score(y_val, logit.predict_proba(X_val_scaled)[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treating Class Imbalance\n",
    "\n",
    "# setup for the ratio argument of RandomOverSampler initialization SMOTE\n",
    "n_pos = np.sum(y_train == 1)\n",
    "n_neg = np.sum(y_train == 0)\n",
    "ratio = {1 : n_pos * 3, 0 : n_neg} \n",
    "\n",
    "smote = imblearn.over_sampling.SMOTE(sampling_strategy = ratio, random_state = 42)\n",
    "\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "nb_smote = BernoulliNB() \n",
    "nb_smote.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "print('Logistic Regression on SMOTE Train Data; Test Recall: %.3f, Test AUC: %.3f' % \\\n",
    "      (recall_score(y_validate, nb_smote.predict(X_validate_scaled)), \n",
    "       roc_auc_score(y_validate, nb_smote.predict_proba(X_validate_scaled)[:,1])))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance\n",
    "\n",
    "importance = logit.coef_[0]\n",
    "\n",
    "# summarize feature importance\n",
    "for i,v in enumerate(importance):\n",
    "\tprint('Feature: %0d, Score: %.5f' % (i,v))\n",
    "    \n",
    "# plot feature importance\n",
    "plt.bar([x for x in range(len(importance))], importance)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_confusion_matrix(model, threshold=0.5):\n",
    "    # Predict class 1 if probability of being in class 1 is greater than threshold\n",
    "    # (model.predict(X_test) does this automatically with a threshold of 0.5)\n",
    "    y_predict = (model.predict_proba(X_test_scaled)[:, 1] >= threshold)\n",
    "    fraud_confusion = confusion_matrix(y_test, y_predict)\n",
    "    plt.figure(dpi=80)\n",
    "    sns.heatmap(fraud_confusion, cmap=plt.cm.BuGn, annot=True, square=True, fmt='d',\n",
    "           xticklabels=['non-vaccinated', 'vaccinated'],\n",
    "           yticklabels=['non-vaccinated', 'vaccinated']);\n",
    "    plt.xlabel('prediction')\n",
    "    plt.ylabel('actual')\n",
    "\n",
    "make_confusion_matrix(rf) #rf = random forest model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=rf.predict(X_test)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\",metrics.precision_score(y_test, y_pred))\n",
    "print(\"Recall:\",metrics.recall_score(y_test, y_pred))\n",
    "print(\"f1:\",metrics.f1_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/emichaelbernardo/titanic/blob/main/Classification.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#simplify Age to 4 groups: Child (0-12), Teen (13-18), Adult (19-65), Senior (66+)\n",
    "\n",
    "def encodeAge(age):\n",
    "    conditions = [age < 13,\n",
    "                  age < 18,\n",
    "                  age < 65,\n",
    "                  age < 100 ]\n",
    "\n",
    "    values = ['Child','Teen','Adult','Senior']\n",
    "    return np.select(conditions, values, default='Adult') \n",
    "\n",
    "df_passengers['AgeGroup'] = df_passengers.Age.apply(encodeAge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at survival rate by Sex, Age and Pclass\n",
    "\n",
    "age = pd.cut(df_passengers['Age'], [0, 12, 17, 64, 80])\n",
    "df_passengers.pivot_table('Survived', ['Sex', age], 'Pclass')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at survival rate by Sex, Age and Embarked\n",
    "\n",
    "df_passengers.pivot_table('Survived', ['Sex', age], 'Embarked')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start Visualizing the Data\n",
    "\n",
    "cols = ['AgeGroup', 'Sex', 'Pclass', 'SibSp', 'Parch', 'Embarked']\n",
    "\n",
    "n_rows = 2\n",
    "n_cols = 3\n",
    "\n",
    "# The subplot grid and the figure size of each graph\n",
    "# This returns a Figure (fig) and an Axes Object (axs)\n",
    "fig, axs = plt.subplots(n_rows, n_cols, figsize=(n_cols*3.2,n_rows*3.2))\n",
    "\n",
    "for r in range(0,n_rows):\n",
    "    for c in range(0,n_cols):  \n",
    "        \n",
    "        i = r*n_cols+ c # index to go through the number of columns       \n",
    "        ax = axs[r][c]  # Show where to position each subplot\n",
    "        sns.countplot(df_passengers[cols[i]], hue=df_passengers[\"Survived\"], ax=ax)\n",
    "        ax.set_title(f'Survival by {cols[i]}' )\n",
    "        ax.legend(title=\"Survived\", loc='upper right') \n",
    "        \n",
    "plt.tight_layout()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the survival rate of each class.\n",
    "sns.barplot(x='Pclass', y='Survived', data=df_passengers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the survival rate of each Sex.\n",
    "sns.barplot(x='Sex', y='Survived', data=df_passengers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at suvival probablity by AgeGroup and Sex\n",
    "sns.barplot(x = 'AgeGroup', y ='Survived', hue='Sex', data = df_passengers)\n",
    "plt.ylabel('Survival Probability')\n",
    "plt.title('Survival Probability by AgeGroup')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at suvival probablity by AgeGroup and Embarked\n",
    "sns.barplot(x = 'Embarked', y ='Survived', hue='Sex', data = df_passengers)\n",
    "plt.ylabel('Survival Probability')\n",
    "plt.title('Survival Probability by Embarked')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View distribution of Passengers\n",
    "sns.factorplot(y = 'Age', x = 'Sex', hue = 'Pclass', kind = 'box', data = df_passengers).set(title='Distribution by Age, Sex and Pclass')\n",
    "sns.factorplot(y = 'Age', x = 'Parch', hue='Sex', kind = 'box', data = df_passengers).set(title='Distribution by Age and Parch')\n",
    "sns.factorplot(y = 'Age', x = 'SibSp', kind = 'box', data = df_passengers).set(title='Distribution by Age and SibSp')\n",
    "sns.factorplot(y = 'Age', x = 'Embarked', kind = 'box', data = df_passengers).set(title='Distribution by Age and Embarked')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Numerically encode categorical features\n",
    "\n",
    "def encode_categorical_features(df):\n",
    "    labelencoder = LabelEncoder()\n",
    "    \n",
    "    # Numerically encode Sex\n",
    "    df.Sex= labelencoder.fit_transform(df.Sex.values)\n",
    "    \n",
    "    # Numerically encode Embarked\n",
    "    df.Embarked= labelencoder.fit_transform(df.Embarked.values)\n",
    "    \n",
    "    # Numerically encode AgeGroup\n",
    "    df.AgeGroup= labelencoder.fit_transform(df.AgeGroup.values)\n",
    "\n",
    "# Encode catergorical features\n",
    "encode_categorical_features(df_modeling)\n",
    "df_modeling\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create functions to score models\n",
    "\n",
    "def accuracy(actuals, preds):\n",
    "    return np.mean(actuals == preds)\n",
    "\n",
    "def precision(actuals, preds):\n",
    "    tp = np.sum((actuals == 1) & (preds == 1))\n",
    "    fp = np.sum((actuals == 0) & (preds == 1))\n",
    "    return tp / (tp + fp)\n",
    "\n",
    "def recall(actuals, preds):\n",
    "    tp = np.sum((actuals == 1) & (preds == 1))\n",
    "    fn = np.sum((actuals == 1) & (preds == 0))\n",
    "    return tp / (tp + fn)\n",
    "\n",
    "def F1(actuals, preds):\n",
    "    p, r = precision(actuals, preds), recall(actuals, preds)\n",
    "    return 2*p*r / (p + r)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[back to top](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Preliminary Visualization<a id='3'></a> \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[back to top](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Preliminary Conclusions<a id='4'></a> \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[back to top](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "288px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
