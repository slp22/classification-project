{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification | MVP\n",
    "\n",
    "# Predicting Heart Disease<a id='top'></a> \n",
    "\n",
    "\n",
    "## **Analysis Goal**  \n",
    "[Research question](#1)\n",
    "\n",
    "## **Process**\n",
    "\n",
    "Classification metric â€“ \n",
    "AUC = determining the 'most at risk' (say top 100) by ordering by liklihood \n",
    "F1/recall = providing a concrete label (either at risk or not at risk) \n",
    "\n",
    "\n",
    "[Dataset](#2)\n",
    "\n",
    "## **Preliminary Visualization**\n",
    "[Visualization](#3)\n",
    "\n",
    "## **Preliminary Conclusions**\n",
    "[Conclusion](#4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import imblearn.over_sampling\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.ensemble import AdaBoostRegressor, RandomForestClassifier\n",
    "from sklearn.linear_model import LinearRegression ,LogisticRegression\n",
    "from sklearn.metrics import *\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB, GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, OrdinalEncoder\n",
    "from sklearn.svm import SVC ,SVR\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.utils import shuffle\n",
    "# from xgboost import XGBClassifier\n",
    "\n",
    "# import plotly.express as px\n",
    "# import plotly.graph_objects as go\n",
    "# from plotly.subplots import make_subplots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Research Question<a id='1'></a> \n",
    "\n",
    "* **RQ:** Could a model predict the probability of a patient having heart disease based on the risk factors in electronic health records?\n",
    "* **Data source:** [Personal Key Indicators of Heart Disease](https://www.kaggle.com/datasets/kamilpytlak/personal-key-indicators-of-heart-disease)\n",
    "* **Error metric:** Recall\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[back to top](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Dataset: [Personal Key Indicators of Heart Disease](https://www.kaggle.com/datasets/kamilpytlak/personal-key-indicators-of-heart-disease)<a id='2'></a>  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('heart_2020_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find nulls\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary statistics on numeric columns\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rename columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename column to not refer to people by their disease\n",
    "df.rename(columns = {'Diabetic':'Diabetes'}, inplace = True)\n",
    "\n",
    "# rename column for readability\n",
    "df.rename(columns = {'AlcoholDrinking':'Alcohol', \n",
    "                     'Smoking': 'Tobacco',\n",
    "                     'AgeCategory':'Age', \n",
    "                     'PhysicalHealth': 'Health_Physical', \n",
    "                     'MentalHealth':'Health_Mental',\n",
    "                     'GenHealth': 'Health_General',\n",
    "                     'DiffWalking': 'Walking',\n",
    "                     'SleepTime': 'Sleep',\n",
    "                     'PhysicalActivity':'Activity',\n",
    "                     'KidneyDisease': 'Kidney',\n",
    "                     'SkinCancer': 'Skin'}, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list unique values by column to see what needs to be coded with numbers/dummy variables\n",
    "\n",
    "for col in df:\n",
    "    print(col, df[col].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 | Map values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_num = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code Y/N to 1/0\n",
    "#     HeartDisease\n",
    "#     Tobacco\n",
    "#     Alcohol \n",
    "#     Stroke\n",
    "#     Walking \n",
    "#     Diabetes -> adjust in next cell for 'borderline diabetes' 'Yes (during pregnancy)'\n",
    "#     Activity\n",
    "#     Asthma \n",
    "#     Kidney \n",
    "#     Skin\n",
    "\n",
    "df_num = df_num.replace({'Yes': 1, 'No': 0}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code categories to nums Diabetes, Sex, Race (alpha), Health_General (poor 1, excellent 5)\n",
    "\n",
    "df_num = df_num.replace({'Yes (during pregnancy)': 2,           #Diabetes\n",
    "                 'No, borderline diabetes': 3,  \n",
    "                 'Female': 1,                                   #Sex \n",
    "                 'Male': 2,                             \n",
    "                 'American Indian/Alaskan Native': 1,           #Race  \n",
    "                 'Asian':2,                     \n",
    "                 'Black':3,                      \n",
    "                 'Hispanic':4,                   \n",
    "                 'Other': 5,                     \n",
    "                 'White': 6,                     \n",
    "                 'Poor': 1,                                     #Health_General\n",
    "                 'Fair': 2,                     \n",
    "                 'Good': 3,                     \n",
    "                 'Very good': 4,                \n",
    "                 'Excellent': 5})               \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code Age to lowest age of category\n",
    "\n",
    "df_num = df_num.replace({'18-24':18,\n",
    "             '25-29':25, \n",
    "             '30-34':30, \n",
    "             '35-39':35, \n",
    "             '40-44':40, \n",
    "             '45-49':45, \n",
    "             '50-54':50,\n",
    "             '55-59':55,\n",
    "             '60-64':60,\n",
    "             '65-69':65,\n",
    "             '70-74':70,\n",
    "             '75-79':75,    \n",
    "             '80 or older':80})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list unique values by column to verify cols coded with numbers\n",
    "\n",
    "for col in df_num :\n",
    "    print(col, df_num[col].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_num.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 | Dummy variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dmy = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dummy variables for non-numerical columns (commented out)\n",
    "df_dmy = pd.get_dummies(data=df_dmy, \n",
    "                        columns=['Sex',                         #Demographics\n",
    "                                 'Age',\n",
    "                                 'Race',           \n",
    "                                 'Activity',                    #Health behaviors\n",
    "#                                  'Sleep', \n",
    "                                 'Alcohol', \n",
    "                                 'Tobacco',\n",
    "#                                  'Health_Physical',           #Health\n",
    "#                                  'Health_Mental', \n",
    "                                 'Health_General', \n",
    "                                 'Walking',\n",
    "#                                  'BMI',\n",
    "                                 'Asthma',                      #Chronic disease                     \n",
    "                                 'Diabetes',\n",
    "                                 'Kidney',\n",
    "                                 'Skin'\n",
    "                                 'Stroke'],\n",
    "                        drop_first=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dmy.head(10)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 | X, y sets for mapped `y_num` `X_num` & dummy `y_dmy` `X_dmy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate target from select features using mapped variables\n",
    "\n",
    "y_num = df_num['HeartDisease'] \n",
    "\n",
    "X_num = df_num.loc[:, ['Sex',            #Demographics\n",
    "               'Age',\n",
    "               'Race',           \n",
    "               'Activity',               #Health behaviors\n",
    "               'Sleep', \n",
    "               'Alcohol', \n",
    "               'Tobacco',\n",
    "               'Health_Physical',        #Health\n",
    "               'Health_Mental', \n",
    "               'Health_General', \n",
    "               'Walking',\n",
    "               'BMI',\n",
    "               'Asthma',                 #Chronic disease\n",
    "               'Diabetes',\n",
    "               'Kidney',\n",
    "               'Skin'\n",
    "               'Stroke']]\n",
    "\n",
    "\n",
    "# separate target from select features using dummy variables\n",
    "y_dmy = df_dmy['HeartDisease']\n",
    "\n",
    "X_dmy = df_dmy.loc[:, ['Sex',            #Demographics\n",
    "               'Age',\n",
    "               'Race',           \n",
    "               'Activity',               #Health behaviors\n",
    "               'Sleep', \n",
    "               'Alcohol', \n",
    "               'Tobacco',\n",
    "               'Health_Physical',        #Health\n",
    "               'Health_Mental', \n",
    "               'Health_General', \n",
    "               'Walking',\n",
    "               'BMI',\n",
    "               'Asthma',                 #Chronic disease\n",
    "               'Diabetes',\n",
    "               'Kidney',\n",
    "               'Skin'\n",
    "               'Stroke']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split test data set using mapped variables\n",
    "X_train_n, X_test_n, y_train_n, y_test_n = train_test_split(X_num, \n",
    "                                                    y_num, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=42)\n",
    "\n",
    "# split test data set\n",
    "X_train_d, X_test_d, y_train_d, y_test_d = train_test_split(X_dmy, \n",
    "                                                    y_dmy, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline rate of target using the mean of training data\n",
    "\n",
    "print('Baseline probability of heart disease (num):', (round(np.mean(y_train_), 4)*100),'%')\n",
    "print('Baseline probability of heart disease (dmy):', (round(np.mean(y_train_n), 4)*100),'%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.pairplot(pd.concat([X_train, y_train], axis=1), hue='HeartDisease');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# picke df, df_num, df_dmy\n",
    "\n",
    "heart_disease_df = df \n",
    "heart_disease_df.to_pickle('heart_disease_df.pkl')\n",
    "\n",
    "heart_disease_df_num = df_num\n",
    "heart_disease_df_num.to_pickle('heart_disease_df_num.pkl')\n",
    "\n",
    "heart_disease_df_dmy = df_dmy\n",
    "heart_disease_df_dmy.to_pickle('heart_disease_df_dmy.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv df, df_num, df_dmy\n",
    "\n",
    "heart_disease_df.to_csv(r'/Users/sandraparedes/Documents/GitHub/metis_dsml/heart_disease_df.csv', index=False)\n",
    "heart_disease_df_num.to_csv(r'/Users/sandraparedes/Documents/GitHub/metis_dsml/heart_disease_df_num.csv', index=False)\n",
    "heart_disease_df_dmy.to_csv(r'/Users/sandraparedes/Documents/GitHub/metis_dsml/heart_disease_df_dmy.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/laramillernm/Metis-Classification-Project/blob/main/TelcoChurnFinal.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model with all features\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "y_pred_lr = logreg.predict(X_test)\n",
    "y_prob_pred_test = logreg.predict_proba(X_test)\n",
    "\n",
    "print(f1_score(y_test, y_pred_lr, average=\"macro\"))\n",
    "\n",
    "\n",
    "# classification report \n",
    "\n",
    "classify_logreg = classification_report(y_test, y_pred_lr)\n",
    "print(classify_logreg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale X_train and X_test\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "# fit decision tree to X_train, y_train\n",
    "\n",
    "classifier = DecisionTreeClassifier(criterion = 'gini', random_state = 0)\n",
    "classifier.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on X_test\n",
    "\n",
    "y_pred_dt = classifier.predict(X_test)\n",
    "print(f1_score(y_test, y_pred_dt, average=\"macro\"))\n",
    "\n",
    "\n",
    "# classification report \n",
    "\n",
    "classify_dt = classification_report(y_test, y_pred_dt)\n",
    "print(classify_dt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/hyewonjng/Metis-Vaccination/blob/main/codes/2_classification_models.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split X and y twice for Xy_train, Xy_test, Xy_validate sets\n",
    "\n",
    "y = df.series\n",
    "X = df.drop(labels = ['column_name', 'column_name'], axis = 1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size = .2, random_state = 42, stratify= y)\n",
    "\n",
    "X_train, X_validate, y_train, y_validate = train_test_split(X_train, y_train, \n",
    "                                                            test_size = .25, random_state = 42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BernoulliNB() \n",
    "\n",
    "# scale X_train \n",
    "std_scale = StandardScaler()\n",
    "X_train_scaled = std_scale.fit_transform(X_train)\n",
    "\n",
    "# fit and score naive bayes Bernoulli model on X_train_scaled, y_train\n",
    "nb = BernoulliNB()\n",
    "nb.fit(X_train_scaled, y_train)\n",
    "nb.score(X_train_scaled, y_train)\n",
    "\n",
    "# validate naive bayes Bernoulli model\n",
    "std_scale = StandardScaler()\n",
    "X_validate_scaled = std_scale.fit_transform(X_validate)\n",
    "\n",
    "# fit and score naive bayes Bernoulli model on X_validate_scaled, y_validate\n",
    "nb = BernoulliNB()\n",
    "nb.fit(X_validate_scaled, y_validate)\n",
    "nb.score(X_validate_scaled, y_validate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BernoulliNB() \n",
    "# predict on X_validate_scaled and score y_validate, y_predict with all metrics\n",
    "\n",
    "y_predict = nb.predict(X_validate_scaled) \n",
    "\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_validate, y_predict))\n",
    "print(\"Precision:\",metrics.precision_score(y_validate, y_predict))\n",
    "print(\"Recall:\",metrics.recall_score(y_validate, y_predict))\n",
    "print(\"F1:\",metrics.f1_score(y_validate, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LogisticRegression()\n",
    "# scale X_train\n",
    "\n",
    "std_scale = StandardScaler()\n",
    "X_train_scaled = std_scale.fit_transform(X_train)\n",
    "\n",
    "logit = LogisticRegression(C=1000) # high C removes regularization\n",
    "logit.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_predict = logit.predict(X_train_scaled) \n",
    "logit.score(X_train_scaled, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LogisticRegression()\n",
    "# scale X_val \n",
    "\n",
    "std_scale = StandardScaler()\n",
    "X_val_scaled = std_scale.fit_transform(X_val)\n",
    "\n",
    "logit = LogisticRegression(C=1000) # high C removes regularization\n",
    "logit.fit(X_val_scaled, y_val)\n",
    "logit.score(X_val_scaled, y_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LogisticRegression()\n",
    "# predict on X_validate_scaled and score y_validate, y_predict with all metrics\n",
    "\n",
    "y_pred = logit.predict(X_validate_scaled) \n",
    "\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_validate, y_predict))\n",
    "print(\"Precision:\",metrics.precision_score(y_validate, y_predict))\n",
    "print(\"Recall:\",metrics.recall_score(y_validate, y_predict))\n",
    "print(\"f1:\",metrics.f1_score(y_validate, y_predict))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_val, logit.predict_proba(X_val_scaled)[:,1])\n",
    "\n",
    "plt.plot(fpr, tpr,lw=2)\n",
    "plt.plot([0,1],[0,1],c='violet',ls='--')\n",
    "plt.xlim([-0.05,1.05])\n",
    "plt.ylim([-0.05,1.05])\n",
    "\n",
    "\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve');\n",
    "print(\"ROC AUC score = \", roc_auc_score(y_val, logit.predict_proba(X_val_scaled)[:,1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class imbalance\n",
    "\n",
    "# setup for the ratio argument of RandomOverSampler initialization SMOTE\n",
    "n_pos = np.sum(y_train == 1)\n",
    "n_neg = np.sum(y_train == 0)\n",
    "ratio = {1 : n_pos * 3, 0 : n_neg} \n",
    "\n",
    "smote = imblearn.over_sampling.SMOTE(sampling_strategy = ratio, random_state = 42)\n",
    "\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "nb_smote = BernoulliNB() \n",
    "nb_smote.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "print('Logistic Regression on SMOTE Train Data; Test Recall: %.3f, Test AUC: %.3f' % \\\n",
    "      (recall_score(y_validate, nb_smote.predict(X_validate_scaled)), \n",
    "       roc_auc_score(y_validate, nb_smote.predict_proba(X_validate_scaled)[:,1])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance\n",
    "\n",
    "importance = logit.coef_[0]\n",
    "\n",
    "# summarize feature importance\n",
    "for i,v in enumerate(importance):\n",
    "    print('Feature: %0d, Score: %.5f' % (i,v))\n",
    "    \n",
    "# plot feature importance\n",
    "plt.bar([x for x in range(len(importance))], importance)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_confusion_matrix(model, threshold=0.5):\n",
    "    \n",
    "    # Predict class 1 if probability of being in class 1 is greater than threshold\n",
    "    # (model.predict(X_test) does this automatically with a threshold of 0.5)\n",
    "    \n",
    "    y_predict = (model.predict_proba(X_test_scaled)[:, 1] >= threshold)\n",
    "    fraud_confusion = confusion_matrix(y_test, y_predict)\n",
    "    plt.figure(dpi=80)\n",
    "    sns.heatmap(fraud_confusion, cmap=plt.cm.BuGn, annot=True, square=True, fmt='d',\n",
    "           xticklabels=['non-vaccinated', 'vaccinated'],\n",
    "           yticklabels=['non-vaccinated', 'vaccinated']);\n",
    "    plt.xlabel('prediction')\n",
    "    plt.ylabel('actual')\n",
    "\n",
    "make_confusion_matrix(rf) #rf = random forest model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\",metrics.precision_score(y_test, y_pred))\n",
    "print(\"Recall:\",metrics.recall_score(y_test, y_pred))\n",
    "print(\"f1:\",metrics.f1_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/emichaelbernardo/titanic/blob/main/Classification.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at survival rate by Sex, Age and Pclass\n",
    "\n",
    "age = pd.cut(df_passengers['Age'], [0, 12, 17, 64, 80])\n",
    "df_passengers.pivot_table('Survived', ['Sex', age], 'Pclass')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at survival rate by Sex, Age and Embarked\n",
    "\n",
    "df_passengers.pivot_table('Survived', ['Sex', age], 'Embarked')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize data\n",
    "\n",
    "cols = ['AgeGroup', 'Sex', 'Pclass', 'SibSp', 'Parch', 'Embarked']\n",
    "\n",
    "n_rows = 2\n",
    "n_cols = 3\n",
    "\n",
    "# The subplot grid and the figure size of each graph\n",
    "# This returns a Figure (fig) and an Axes Object (axs)\n",
    "fig, axs = plt.subplots(n_rows, n_cols, figsize=(n_cols*3.2,n_rows*3.2))\n",
    "\n",
    "for r in range(0,n_rows):\n",
    "    for c in range(0,n_cols):  \n",
    "        \n",
    "        i = r*n_cols+ c # index to go through the number of columns       \n",
    "        ax = axs[r][c]  # Show where to position each subplot\n",
    "        sns.countplot(df_passengers[cols[i]], hue=df_passengers[\"Survived\"], ax=ax)\n",
    "        ax.set_title(f'Survival by {cols[i]}' )\n",
    "        ax.legend(title=\"Survived\", loc='upper right') \n",
    "        \n",
    "plt.tight_layout()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the survival rate of each class\n",
    "sns.barplot(x='Pclass', y='Survived', data=df_passengers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the survival rate of each Sex\n",
    "sns.barplot(x='Sex', y='Survived', data=df_passengers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at suvival probablity by AgeGroup and Sex\n",
    "sns.barplot(x = 'AgeGroup', y ='Survived', hue='Sex', data = df_passengers)\n",
    "plt.ylabel('Survival Probability')\n",
    "plt.title('Survival Probability by AgeGroup')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at suvival probablity by AgeGroup and Embarked\n",
    "sns.barplot(x = 'Embarked', y ='Survived', hue='Sex', data = df_passengers)\n",
    "plt.ylabel('Survival Probability')\n",
    "plt.title('Survival Probability by Embarked')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View distribution of passengers\n",
    "sns.factorplot(y = 'Age', x = 'Sex', hue = 'Pclass', kind = 'box', data = df_passengers).set(title='Distribution by Age, Sex and Pclass')\n",
    "sns.factorplot(y = 'Age', x = 'Parch', hue='Sex', kind = 'box', data = df_passengers).set(title='Distribution by Age and Parch')\n",
    "sns.factorplot(y = 'Age', x = 'SibSp', kind = 'box', data = df_passengers).set(title='Distribution by Age and SibSp')\n",
    "sns.factorplot(y = 'Age', x = 'Embarked', kind = 'box', data = df_passengers).set(title='Distribution by Age and Embarked')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions to score models\n",
    "\n",
    "def accuracy(actuals, preds):\n",
    "    return np.mean(actuals == preds)\n",
    "\n",
    "def precision(actuals, preds):\n",
    "    tp = np.sum((actuals == 1) & (preds == 1))\n",
    "    fp = np.sum((actuals == 0) & (preds == 1))\n",
    "    return tp / (tp + fp)\n",
    "\n",
    "def recall(actuals, preds):\n",
    "    tp = np.sum((actuals == 1) & (preds == 1))\n",
    "    fn = np.sum((actuals == 1) & (preds == 0))\n",
    "    return tp / (tp + fn)\n",
    "\n",
    "def F1(actuals, preds):\n",
    "    p, r = precision(actuals, preds), recall(actuals, preds)\n",
    "    return 2*p*r / (p + r)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[back to top](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Preliminary Visualization<a id='3'></a> \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[back to top](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Preliminary Conclusions<a id='4'></a> \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[back to top](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "288px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
