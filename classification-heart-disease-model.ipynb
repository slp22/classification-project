{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69987c01",
   "metadata": {},
   "source": [
    "#### Classification | Model\n",
    "\n",
    "# Predicting Heart Disease  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7f9750",
   "metadata": {},
   "source": [
    "## Classification Model Stepwise Analysis <a id='top'></a> \n",
    "\n",
    "1. [Research Question](#1)<br/>\n",
    "2. [DataFrames](#2) <br/>\n",
    "3. [Exporatory Data Analysis](#3)<br/>\n",
    "    Summarize<br/>\n",
    "    Classification Viability<br/>\n",
    "    Classification Metrics<br/>\n",
    "4. [Baselining](#4)<br/>\n",
    "5. [Validation](#5)<br/>\n",
    "6. [Model Iterations](#6) <br/>\n",
    "    model 1<br/>\n",
    "    model 1<br/>\n",
    "    model 1<br/>\n",
    "    model 1<br/>\n",
    "    model 1<br/>\n",
    "    model 1<br/>\n",
    "    [Feature Engineering](#68)<br/>\n",
    "    Class Imbalance<br/>\n",
    "7. [Model Selection ](#7)<br/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2b0a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import imblearn.over_sampling\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline\n",
    "np.set_printoptions(suppress=True) \n",
    "\n",
    "from ipywidgets import interactive, FloatSlider\n",
    "from plotly.subplots import make_subplots\n",
    "from sklearn import tree\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.ensemble import AdaBoostRegressor, RandomForestClassifier\n",
    "from sklearn.linear_model import LinearRegression ,LogisticRegression\n",
    "from sklearn.metrics import *\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, train_test_split\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB, GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, OrdinalEncoder\n",
    "from sklearn.svm import SVC ,SVR\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.utils import shuffle\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, precision_recall_curve,f1_score, fbeta_score\n",
    "\n",
    "iris_dataset = datasets.load_iris()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa472b2",
   "metadata": {},
   "source": [
    "## 1 | Research Design<a id='1'></a> \n",
    "\n",
    "* **Reserach Question:** How might we predict which patients are at high risk of heart disease?\n",
    "* **Impact Hypothesis:** Reduce the number of patients who develop heart disease (arterial plaque or heart attack).\n",
    "* **Data source:** [Personal Key Indicators of Heart Disease](https://www.kaggle.com/datasets/kamilpytlak/personal-key-indicators-of-heart-disease), n=319,795\n",
    "* **Error metric:** [Recall](#3c) and [ROC AUC](#3c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a984a11a",
   "metadata": {},
   "source": [
    "#### [Data Dictionary](https://www.cdc.gov/brfss/annual_data/2020/pdf/codebook20_llcp-v2-508.pdf)<a id='1a'></a>\n",
    "_Target_\n",
    "- `y_heart_disease`: Y/N | coronary heart disease (CHD) or myocardial infarction (MI)\n",
    "\n",
    "_Health Behaviors_\n",
    "- `behavior_activity`: Num (0-30) | # days did physical activity/ exercise other than regular job\n",
    "- `behavior_alcohol`: Y/N | heavy drinker, defined as men: 14+/wk, women: 7+/wk (includes beer, wine, malt beverage, liquor)\n",
    "- `behavior_sleep`: Num (0-24) | # hours of sleep in a 24-hour period, on average\n",
    "- `behavior_tobacco`: Y/N | smoked at least 100 cigarettes in your life\n",
    "\n",
    "_Demographics_\n",
    "- `demg_age`: 18-24, 25-29, 30-34, 35-39, 40-44, 45-49, 50-54, 55-59, 60-64, 65-69, 70-74, 75-79, 80+\n",
    "- `demg_gender`: male/female\n",
    "- `demg_race`: White, Black, Asian, American Indian/Alaskan Native, Hispanic, Other race\n",
    "\n",
    "_Health Measures_\n",
    "- `health_bmi`: Num | Body Mass Index (BMI)\n",
    "- `health_physical`: Num (0-30) | # days physical health  not good, includes physical illness and injury\n",
    "- `health_mental`: Num (0-30 ) | # days mental health not good, includes stress, depression, and problems with emotions\n",
    "- `health_general`: Excellent, Very Good, Fair, Poor | Would you say that in general your health is...\n",
    "- `health_mobility`: Y/N | serious difficulty walking or climbing stairs\n",
    "\n",
    "_Chronic Disease_\n",
    "- `disease_asthma`: Y/N\n",
    "- `disease_diabetes`: Y/N/Y pregnancy/N borderline\n",
    "- `disease_kidney`: Y/N | kidney disease, excludes kidney stones, bladder infection or incontinence\n",
    "- `disease_skin`: Y/N | skin cancer\n",
    "- `disease_stroke`: Y/N"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f17f49",
   "metadata": {},
   "source": [
    "[back to top](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35969908",
   "metadata": {},
   "source": [
    "## 2 | [DataFrames](https://github.com/slp22/classification-project/blob/main/classification-heart-disease_mvp.ipynb)<a id='2'></a>  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74246ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load clean and transformed dataframes from mvp \n",
    "heart_disease_df = pd.read_csv('heart_disease_df.csv')\n",
    "heart_disease_df_map = pd.read_csv('heart_disease_df_map.csv') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6760b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean df\n",
    "heart_disease_df.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659590fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformed df: mapped categorical variables to numerical values \n",
    "heart_disease_df_map.head(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f81cb7e6",
   "metadata": {},
   "source": [
    "[back to top](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6983cdb",
   "metadata": {},
   "source": [
    "## 3 | Exporatory Data Analysis<a id='3'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cdd76aa",
   "metadata": {},
   "source": [
    "#### Using `heart_disease_df_map` with mapped variables for modeling.\n",
    "##### Note: Full EDA part of [MVP](https://github.com/slp22/classification-project/blob/main/classification-heart-disease_mvp.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5e792a",
   "metadata": {},
   "source": [
    "### 3.1 Summarize data<a id='31'></a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d208109a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe info\n",
    "heart_disease_df_map.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05ed68f",
   "metadata": {},
   "source": [
    "#### No missing data, all data types are numerical."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a2bfd6",
   "metadata": {},
   "source": [
    "[back to top](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d6ea2d",
   "metadata": {},
   "source": [
    "### 3.2 Classification viability<a id='32'></a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69813756",
   "metadata": {},
   "outputs": [],
   "source": [
    "# descriptive statistics\n",
    "heart_disease_df_map.describe().T.style.background_gradient(cmap='Blues')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7274fb9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation matrix\n",
    "heart_disease_df_map.corr().style.background_gradient(cmap='Blues')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f0dca5",
   "metadata": {},
   "source": [
    "#### A classification model is viable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81bb0dab",
   "metadata": {},
   "source": [
    "[back to top](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de33d58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target vs age\n",
    "ax = sns.boxplot(x='y_heart_disease', y='demg_age', data=heart_disease_df_map)\n",
    "ax.set_xticklabels(['No', 'Yes']);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9c4496",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target vs mobility\n",
    "sns.boxplot(x='y_heart_disease', y='health_bmi', data=heart_disease_df_map)\n",
    "ax.set_xticklabels(['No', 'Yes']);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed54dfa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target vs physical health\n",
    "sns.boxplot(x='y_heart_disease', y='health_physical', data=heart_disease_df_map)\n",
    "ax.set_xticklabels(['No', 'Yes']);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5d4d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target distribution\n",
    "print('Positives/Negatives Ratio:', round(27373/292422, 4) * 100, '%')\n",
    "print(heart_disease_df['y_heart_disease'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90d7cac",
   "metadata": {},
   "source": [
    "[back to top](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c7ed45",
   "metadata": {},
   "source": [
    "### 3.3 Classification metrics<a id='33'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae9fb9b",
   "metadata": {},
   "source": [
    "* **Recall** to maximize on patients who are true positives for heart disease.\n",
    "* **ROC AUC** to identify high vs low risk patients. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a71be59",
   "metadata": {},
   "source": [
    "[back to top](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c710fb",
   "metadata": {},
   "source": [
    "## 4 | Baseline<a id='4'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1678c1ca",
   "metadata": {},
   "source": [
    "#### Logistic regression with three features based on correlation matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37677e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate target from features based on the correlation matrix\n",
    "y_base = heart_disease_df_map['y_heart_disease'] \n",
    "X_base = heart_disease_df_map.loc[:, [\n",
    "#     'behavior_activity', \n",
    "#     'behavior_alcohol', \n",
    "#     'behavior_sleep',\n",
    "#     'behavior_tobacco',\n",
    "    'demg_age',\n",
    "#     'demg_gender', \n",
    "#     'demg_race',\n",
    "#     'disease_asthma', \n",
    "#     'disease_diabetes', \n",
    "#     'disease_kidney', \n",
    "#     'disease_skin', \n",
    "#     'disease_stroke', \n",
    "#     'health_bmi', \n",
    "#     'health_general', \n",
    "#     'health_mental',\n",
    "    'health_mobility', \n",
    "    'health_physical'\n",
    "    ]]\n",
    "\n",
    "# split baseline data test/train/validate\n",
    "X_train_base, X_test_base, y_train_base, y_test_base = train_test_split(X_base,\n",
    "                                                                        y_base,\n",
    "                                                                        test_size=0.2,\n",
    "                                                                        random_state=42)\n",
    "X_train_base, X_validate_base, y_train_base, y_validate_base = train_test_split(X_train_base, \n",
    "                                                                                y_train_base, \n",
    "                                                                                test_size = .25, \n",
    "                                                                                random_state = 42)\n",
    "\n",
    "# scale baseline X train/test\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled_base = scaler.fit_transform(X_train_base)\n",
    "X_test_scaled_base = scaler.transform(X_test_base)\n",
    "X_validate_scaled_base = scaler.transform(X_validate_base)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eac6c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline logistic regression X train scaled & y train\n",
    "log_reg_base = LogisticRegression().fit(X_train_scaled_base, y_train_base)\n",
    "\n",
    "# baseline predict on X_validate_scaled_m \n",
    "y_pred_base = logreg_base.predict(X_validate_scaled_base) \n",
    "\n",
    "\n",
    "# score on X_test_scaled and y_test\n",
    "print(\"Baseline logistic regression recall:\", round(\n",
    "    recall_score(log_reg_base.predict(X_validate_scaled_base), y_validate_base), 4))\n",
    "\n",
    "print(\"Baseline logistic regression ROC AUC score (val):\",  round(\n",
    "    roc_auc_score(y_validate_base, log_reg_base.predict_proba(X_validate_scaled_base)[:,1]), 4))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33917bdd",
   "metadata": {},
   "source": [
    "[back to top](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6f8fac",
   "metadata": {},
   "source": [
    "## 5 | Validation<a id='5'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0c37fa",
   "metadata": {},
   "source": [
    "#### Validation and testing scheme to use in [model selection](#7). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad7c7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate target from features \n",
    "y = heart_disease_df_map['y_heart_disease'] \n",
    "X = heart_disease_df_map.loc[:, [\n",
    "    'behavior_activity', \n",
    "    'behavior_alcohol', \n",
    "    'behavior_sleep',\n",
    "    'behavior_tobacco',\n",
    "    'demg_age',\n",
    "    'demg_gender', \n",
    "    'demg_race',\n",
    "    'disease_asthma', \n",
    "    'disease_diabetes', \n",
    "    'disease_kidney', \n",
    "    'disease_skin', \n",
    "    'disease_stroke', \n",
    "    'health_bmi', \n",
    "    'health_general', \n",
    "    'health_mental',\n",
    "    'health_mobility', \n",
    "    'health_physical'\n",
    "    ]]\n",
    "\n",
    "# split data test/train/validate\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=42)\n",
    "X_train, X_validate, y_train, y_validate = train_test_split(X_train, \n",
    "                                                            y_train, \n",
    "                                                            test_size = .25, \n",
    "                                                            random_state = 42)\n",
    "\n",
    "# scale X train/test/validate\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_validate_scaled = scaler.transform(X_validate)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3822eed6",
   "metadata": {},
   "source": [
    "[back to top](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1a1148",
   "metadata": {},
   "source": [
    "## 6 | Model Iterations <a id='6'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2dc5899",
   "metadata": {},
   "source": [
    "- Starting from the baseline and in an iterative, validated loop ask: \n",
    "    - Do you need more complexity or less (underfitting vs. overfitting)? \n",
    "    - Do you need a fancier model (nonlinear, additional feature engineering / transformations)? \n",
    "    - If you need more complexity, try tree-based models such as random forest or gradient boosted trees. \n",
    "    - Are you overfitting and need to make your model more conservative by removing features or using regularization? - Hopefully you can quickly acquire an understanding of which direction you need to go in from your baseline and early modeling results, then make more fine-tuned changes as you go.\n",
    "\n",
    "\n",
    "- The impact of model choices should be consistently measured against the same validation data as in part 3, using your relevant classification performance metrics such as F1 or ROC AUC. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a3323e",
   "metadata": {},
   "source": [
    "[back to top](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3ef44d",
   "metadata": {},
   "source": [
    "### 6.1 k-Nearest Neighbors<a id='61'></a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0783404b",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# print(\"The score for kNN is\")\n",
    "print(\"Training: {:6.2f}%\".format(100*knn.score(X_train, y_train)))\n",
    "# print(\"Test set: {:6.2f}%\".format(100*knn.score(X_test, y_test)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09011a22",
   "metadata": {},
   "source": [
    "[back to top](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7feeffa",
   "metadata": {},
   "source": [
    "### 6.2 Logistic Regression<a id='62'></a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95db7d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression().fit(X_train_scaled, y_train)\n",
    "y_pred_log_reg = log_reg.predict(X_validate_scaled) \n",
    "\n",
    "print(\"Logistic regression recall score (val):\", round(\n",
    "    recall_score(log_reg.predict(X_validate_scaled), y_validate), 4))\n",
    "print(\"Logistic regression ROC AUC score (val):\",  round(\n",
    "    roc_auc_score(y_validate, log_reg.predict_proba(X_validate_scaled)[:,1]), 4))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c286909",
   "metadata": {},
   "source": [
    "Logistic regression maybe [model winner](#7), recall score improved from [baseline](#4).<br/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39d97de",
   "metadata": {},
   "source": [
    "[back to top](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e80998b",
   "metadata": {},
   "source": [
    "### 6.3 Decision Trees<a id='63'></a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ab90c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tree max depth 2\n",
    "dt = DecisionTreeClassifier(max_depth=2,criterion=\"entropy\")\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred = dt.predict(X_validate)\n",
    "\n",
    "print(\"Decision tree (depth=2) recall (val):\", round(\n",
    "    recall_score(dt.predict(X_validate), y_validate), 4))\n",
    "tree.plot_tree(dt);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac35669d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tree max depth 4\n",
    "dt = DecisionTreeClassifier(max_depth=4,criterion=\"entropy\")\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred = dt.predict(X_validate)\n",
    "\n",
    "print(\"Decision tree (depth=4) recall score (val):\", round(\n",
    "    recall_score(dt.predict(X_validate), y_validate), 4))\n",
    "tree.plot_tree(dt);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4269a34f",
   "metadata": {},
   "source": [
    "### 6.4 Random Forests <a id='64'></a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dac965d",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = RandomForestClassifier().fit(X_train, y_train)\n",
    "y_pred_rf = forest.predict(X_validate)\n",
    "\n",
    "print(\"Random forestes recall score (val):\", round(\n",
    "    recall_score(forest.predict(X_validate), y_validate), 4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c20d5e5",
   "metadata": {},
   "source": [
    "Random forest model performs worse than [logistic regression](#6b). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d5f2337",
   "metadata": {},
   "source": [
    "[back to top](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb5d266",
   "metadata": {},
   "source": [
    "### 6.5 Gradient Boosted Trees: xgboost<a id='65'></a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f4e3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### code block"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30ccd64",
   "metadata": {},
   "source": [
    "[back to top](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b98422c",
   "metadata": {},
   "source": [
    "### 6.6 Ensemble<a id='66'></a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae903622",
   "metadata": {},
   "outputs": [],
   "source": [
    "### code block"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac96809",
   "metadata": {},
   "source": [
    "[back to top](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1402028c",
   "metadata": {},
   "source": [
    "### 6.7. Naive Bayes<a id='67'></a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356ffcc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BernoulliNB() \n",
    "nb = BernoulliNB().fit(X_train_scaled, y_train)\n",
    "y_predict_nb = nb.predict(X_validate_scaled) \n",
    "print(\"Bernoulli NB recall score (val):\", round(\n",
    "    recall_score(nb.predict(X_validate), y_validate), 4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3545ba",
   "metadata": {},
   "source": [
    "[back to top](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c638f89",
   "metadata": {},
   "source": [
    "### 6.8 Feature Engineering <a id='68'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a521d88d",
   "metadata": {},
   "source": [
    "### New features A: question groups\n",
    "Groups of similar survey question questions as defined by [data dictionary](https://www.cdc.gov/brfss/annual_data/2020/pdf/codebook20_llcp-v2-508.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb50fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 behaviors = phyiscial activity days/month + sleep time hrs/day + alcohol + tobacco use\n",
    "heart_disease_df_map['behaviors'] = (\n",
    "    heart_disease_df_map['behavior_activity'] +\n",
    "    heart_disease_df_map['behavior_alcohol'] +  \n",
    "    heart_disease_df_map['behavior_sleep'] +\n",
    "    heart_disease_df_map['behavior_tobacco'])\n",
    "\n",
    "# 2 demographics = age + gender + race\n",
    "heart_disease_df_map['demographics'] = (\n",
    "    heart_disease_df_map['demg_age'] +\n",
    "    heart_disease_df_map['demg_gender'] +  \n",
    "    heart_disease_df_map['demg_race'])\n",
    "\n",
    "# 3 disease = asthma + diabetes + kidney + skin cancer + stroke\n",
    "heart_disease_df_map['disease'] = (\n",
    "    heart_disease_df_map['disease_asthma'] +\n",
    "    heart_disease_df_map['disease_diabetes'] +  \n",
    "    heart_disease_df_map['disease_kidney'] +\n",
    "    heart_disease_df_map['disease_skin'] +\n",
    "    heart_disease_df_map['disease_stroke'])\n",
    "\n",
    "# 4 (health) measures = asthma + diabetes + kidney + skin cancer + stroke\n",
    "heart_disease_df_map['measures'] = (\n",
    "    heart_disease_df_map['health_bmi'] +\n",
    "    heart_disease_df_map['health_general'] +  \n",
    "    heart_disease_df_map['health_mental'] +\n",
    "    heart_disease_df_map['health_mobility'] +\n",
    "    heart_disease_df_map['health_physical'])\n",
    "\n",
    "heart_disease_df_map.columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae7953d",
   "metadata": {},
   "source": [
    "### New features B: risk factors\n",
    "Heart disease risk factors by [CDC](https://www.cdc.gov/heartdisease/facts.htm). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c09d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# risk factors = diabetes + bmi + physical activity + alcohol\n",
    "    heart_disease_df_map['risk_factors'] = (\n",
    "    heart_disease_df_map['disease_diabetes'] +\n",
    "    heart_disease_df_map['health_bmi'] +  \n",
    "    heart_disease_df_map['behavior_activity'] +\n",
    "    heart_disease_df_map['behavior_alcohol'])\n",
    "\n",
    "heart_disease_df_map.columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a6e8da",
   "metadata": {},
   "source": [
    "### Logistic regression A: question groups<a id='68a'></a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04afa725",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate target from question groups features: y/X_f\n",
    "y_f = heart_disease_df_map['y_heart_disease'] \n",
    "X_f = heart_disease_df_map.loc[:, ['behaviors', \n",
    "                                   'demographics', \n",
    "                                   'disease', \n",
    "                                   'measures']]\n",
    "\n",
    "# split data test/train/validate\n",
    "X_train_f, X_test_f, y_train_f, y_test_f = train_test_split(X_f, \n",
    "                                                    y_f, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=42)\n",
    "\n",
    "X_train_f, X_validate_f, y_train_f, y_validate_f = train_test_split(X_train_f, \n",
    "                                                                    y_train_f, \n",
    "                                                                    test_size = .25, \n",
    "                                                                    random_state = 42)\n",
    "# scale X train/test/validate\n",
    "scaler = StandardScaler()\n",
    "X_train_f_scaled = scaler.fit_transform(X_train_f)\n",
    "X_test_f_scaled = scaler.transform(X_test_f)\n",
    "X_validate_f_scaled = scaler.transform(X_validate_f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7509ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LR question groups features\n",
    "log_reg_f = LogisticRegression().fit(X_train_f_scaled, y_train_f)\n",
    "y_pred_f = log_reg_f.predict(X_validate_f_scaled) \n",
    "print(\"Logistic regression only engineered features recall:\", round(\n",
    "    recall_score(log_reg_f.predict(X_validate_f_scaled), y_validate_f), 4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8ab392",
   "metadata": {},
   "source": [
    "Logistic regression with only engineered features performs worse than first iteration of [logistic regression](#6b). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2b5bd6",
   "metadata": {},
   "source": [
    "### Logistic regression B: risk factors<a id='68b'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e35285e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate target from engineered features: y/X_rf\n",
    "y_rf = heart_disease_df_map['y_heart_disease'] \n",
    "X_rf = heart_disease_df_map.loc[:, ['disease_diabetes',\n",
    "                                    'health_bmi',\n",
    "                                    'behavior_activity', \n",
    "                                   'behavior_alcohol']]\n",
    "\n",
    "# split data test/train/validate\n",
    "X_train_rf, X_test_rf, y_train_rf, y_test_rf = train_test_split(X_rf, \n",
    "                                                    y_rf, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=42)\n",
    "\n",
    "X_train_rf, X_validate_rf, y_train_rf, y_validate_rf = train_test_split(X_train_rf, \n",
    "                                                                        y_train_rf, \n",
    "                                                                        test_size = .25, \n",
    "                                                                        random_state = 42)\n",
    "# scale X train/test/validate\n",
    "scaler = StandardScaler()\n",
    "X_train_rf_scaled = scaler.fit_transform(X_train_rf)\n",
    "X_test_rf_scaled = scaler.transform(X_test_rf)\n",
    "X_validate_rf_scaled = scaler.transform(X_validate_rf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec53f6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LR risk factor features\n",
    "log_reg_rf = LogisticRegression().fit(X_train_rf_scaled, y_train_rf)\n",
    "y_pred_rf = log_reg_rf.predict(X_validate_rf_scaled) \n",
    "print(\"Logistic regression only engineered features recall:\", round(\n",
    "    recall_score(log_reg_rf.predict(X_validate_rf_scaled), y_validate_rf), 4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748d462a",
   "metadata": {},
   "source": [
    "Logistic regression with risk factor features performs `better/worse` than [logistic regression ...](#6..) and `better/worse` than [logistic regression ...](#6..). \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "047a4cdc",
   "metadata": {},
   "source": [
    "[back to top](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf977e38",
   "metadata": {},
   "source": [
    "### Logistic regression AB: question groups + risk factors features<a id='68ab'></a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529ed6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate target from question groups + risk factor features: y/X_new\n",
    "y_new = heart_disease_df_map['y_heart_disease'] \n",
    "X_new = heart_disease_df_map.loc[:, [\n",
    "    'behaviors', \n",
    "    'demographics', \n",
    "    'disease', \n",
    "    'measures',\n",
    "    'behavior_activity',\n",
    "    'behavior_alcohol'\n",
    "    'disease_diabetes',\n",
    "    'health_bmi'\n",
    "    ]]\n",
    "\n",
    "# split data test/train/validate\n",
    "X_train_new, X_test_new, y_train_new, y_test_new = train_test_split(X_new, \n",
    "                                                    y_new, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=42)\n",
    "X_train_new, X_validate_new, y_train_new, y_validate_new = train_test_split(X_train_new, \n",
    "                                                                            y_train_new, \n",
    "                                                                            test_size = .25, \n",
    "                                                                            random_state = 42)\n",
    "\n",
    "# Scale X train/test/validate\n",
    "scaler = StandardScaler()\n",
    "X_train_new_scaled = scaler.fit_transform(X_train_new)\n",
    "X_test_new_scaled = scaler.transform(X_test_new)\n",
    "X_validate_new_scaled = scaler.transform(X_validate_new)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d86fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LR question groups + risk factor features\n",
    "log_reg_ff = LogisticRegression().fit(X_train_ff_scaled, y_train_ff)\n",
    "y_pred_ff = log_reg_ff.predict(X_validate_ff_scaled) \n",
    "print(\"Logistic regression recall:\", round(\n",
    "    recall_score(log_reg_ff.predict(X_validate_ff_scaled), y_validate_ff), 4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8760b990",
   "metadata": {},
   "source": [
    "Logistic regression with data dictionary and risk factor features performs `better/worse` than [logistic regression ...](#6..) and `better/worse` than [logistic regression ...](#6..). \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affaacbb",
   "metadata": {},
   "source": [
    "[back to top](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2236494a",
   "metadata": {},
   "source": [
    "## Class Imblance Handling <a id='6g'></a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b424511",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target imbalance\n",
    "heart_disease_df_map.y_heart_disease.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3179ece2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resample?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399496cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class_weight adjustments\n",
    "# _sklearn fbeta score – f2 or f3 to upweight recall_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19293aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# decision threshold to max recall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "713e8c49",
   "metadata": {},
   "source": [
    "[back to top](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ed3627",
   "metadata": {},
   "source": [
    "## 7 | Model Selection<a id='7'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8af3efb",
   "metadata": {},
   "source": [
    "#### Model winner: [logistic regression](#6b), validate and test using [scheme](#5) presented above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18293b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# precision and recall curves\n",
    "\n",
    "precision_curve, recall_curve, threshold_curve = precision_recall_curve(\n",
    "    y_test, log_reg.predict_proba(X_test)[:,1] )\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "f, ax = plt.subplots(figsize=(10, 6))\n",
    "plt.plot(threshold_curve, precision_curve[1:],label='precision')\n",
    "plt.plot(threshold_curve, recall_curve[1:], label='recall')\n",
    "plt.legend(loc='center')\n",
    "plt.xlabel('Threshold');\n",
    "plt.title('Precision and Recall Curves')\n",
    "plt.savefig(\"precision-recall-curves.jpeg\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3518e741",
   "metadata": {},
   "source": [
    "### 7.1 Finalize and test<a id='71'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5c1d3d",
   "metadata": {},
   "source": [
    "- When satisfied with the results of your tuning in _Model Iterations_, establish your final model choices:\n",
    "        - features, \n",
    "        - preprocessing, \n",
    "        - imbalance handling strategy, and \n",
    "        - hyperparameters\n",
    "    - retrain this model on all training + validation data. \n",
    "- Make predictions on the test data and score these predictions, reporting this score as your estimate of the model's generalization performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7363ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix on y_validate, y_pred_log_reg\n",
    "cm = confusion_matrix(y_validate, y_pred_log_reg)\n",
    "\n",
    "f, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "ax = sns.heatmap(cm/np.sum(cm),fmt='.2%', annot=True, cmap='Reds')\n",
    "\n",
    "ax.xaxis.set_ticklabels(['Predicted Heart Disease','Predicted Healthy'])            #double check x y labels\n",
    "ax.yaxis.set_ticklabels(['True Heart Disease','True Healthy'])\n",
    "\n",
    "plt.title('Confusion Matrix (y_val, y_pred)')\n",
    "ax.set_xlabel('Predicted')\n",
    "ax.set_ylabel('Actual ')\n",
    "\n",
    "plt.savefig(\"confusion-matrix.jpeg\");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134fe81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification report on y_validate/predict\n",
    "print(classification_report(y_validate, \n",
    "                            y_pred_log_reg, \n",
    "                            target_names=['no heart disease', 'yes heart disease']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670f6dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC AUC curve\n",
    "# calculate the fpr and tpr for all thresholds of the classification\n",
    "probs = log_reg.predict_proba(X_test)\n",
    "preds = probs[:,1]\n",
    "fpr, tpr, threshold = roc_curve(y_test, preds)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "f, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "\n",
    "plt.title('ROC AUC Curve')\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "\n",
    "plt.savefig(\"roc-auc-curve.jpeg\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74008910",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature importance\n",
    "imp_feat = pd.DataFrame()\n",
    "feat = list(X)\n",
    "imp = log_reg.coef_[0]\n",
    "imp_feat['Feature'] = feat\n",
    "imp_feat['Importance'] = imp\n",
    "imp_feat.sort_values(by=['Importance'], ascending=False, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3096fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vizualize feature importance\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "f, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "sns.barplot(x='Importance', y='Feature', data=imp_feat, color='red');\n",
    "plt.title('Feature Importance')\n",
    "\n",
    "plt.savefig(\"feature-importance.jpeg\");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6b507e",
   "metadata": {},
   "source": [
    "### 7.2 Interpret<a id='72'></a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c181c5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# persona 1: couch potato, drinks every day, high BMI, has diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ddcfb81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# persona 2: runner, drinks every day, normal BMI, bordrline diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1cc2489",
   "metadata": {},
   "outputs": [],
   "source": [
    "# persona 3: walks to works, social drinker, normal BMI, no diabetes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7454c591",
   "metadata": {},
   "source": [
    "[back to top](#top)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
